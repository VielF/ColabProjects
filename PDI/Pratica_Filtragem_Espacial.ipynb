{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VielF/ColabProjects/blob/main/Pr%C3%A1tica_Filtragem_Espacial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A4cGaP0THOB"
      },
      "source": [
        "Universidade do Vale do Itajaí<br>\n",
        "Escola Politécnica<br>\n",
        "Processamento Digital de Sinais: Imagens\n",
        "\n",
        "# Exercício Avalitivo de Filtragem Espacial\n",
        "\n",
        "### Tutoriais da OpenCV\n",
        "\n",
        "- https://docs.opencv.org/master/d9/df8/tutorial_root.html\n",
        "- https://www.geeksforgeeks.org/opencv-python-tutorial/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNEPMubMTHOC"
      },
      "source": [
        "## Conversão de imagem RGB em imagem Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V9LgCTiuTHOD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ls0tquF8THOD"
      },
      "outputs": [],
      "source": [
        "#abria a imagem\n",
        "img = cv2.imread('data/t1_10x5.jpg',1)\n",
        "#cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6cCMWllFTHOE"
      },
      "outputs": [],
      "source": [
        "#mostrando a imagem colorida\n",
        "cv2.imshow('in', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H_qCe356THOE"
      },
      "outputs": [],
      "source": [
        "#aplicando conversão básica\n",
        "#numpy\n",
        "#img_grayscale_basic = (img[ : , : ,0]+img[ : , : ,1]+img[ : , : ,2])/3\n",
        "\n",
        "#cv2\n",
        "B, G, R = cv2.split(img)\n",
        "img_grayscale_basic = (B+G+R)/3\n",
        "\n",
        "img_grayscale_basic = np.array(img_grayscale_basic, dtype=np.uint8)\n",
        "\n",
        "cv2.imshow('img_grayscale_basic', img_grayscale_basic)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "h5xJiS7ETHOE"
      },
      "outputs": [],
      "source": [
        "#aplicando conversão ponderada\n",
        "#img_grayscale_basic = 0.299*img[ : , : ,0] + 0.587*img[ : , : ,1] + 0.114*img[ : , : ,2]\n",
        "\n",
        "#cv2\n",
        "B, G, R = cv2.split(img)\n",
        "img_grayscale_pondered = 0.299*B+0.587*G+0.114*R\n",
        "\n",
        "img_grayscale_pondered = np.array(img_grayscale_pondered, dtype=np.uint8)\n",
        "\n",
        "cv2.imshow('img_grayscale_basic', img_grayscale_pondered)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Q8z4jJTHOF"
      },
      "source": [
        "## Filtro Espacial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V8CV7s2jTHOF"
      },
      "outputs": [],
      "source": [
        "def gauss_create(sigma=1, size_x=3, size_y=3):\n",
        "    '''\n",
        "    Create normal (gaussian) distribuiton\n",
        "    '''\n",
        "    x, y = np.meshgrid(np.linspace(-1,1,size_x), np.linspace(-1,1,size_y))\n",
        "    calc = 1/((2*np.pi*(sigma**2)))\n",
        "    exp = np.exp(-(((x**2) + (y**2))/(2*(sigma**2))))\n",
        "    \n",
        "    return exp*calc\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9wenP4STHOF"
      },
      "source": [
        "### Suavização\n",
        "\n",
        "1. Implemente a sua própria convolução manualmente, em formato de função, utilizando os conceitos vistos em aula\n",
        "2. Aplique a filtragem de suavização, com as máscaras 3x3, 5x5 e 7x7, com os filtros:\n",
        " - média\n",
        " - gaussino (escolha uma distribuição adequada, podendo utilizar a função acima ou recuperando a distribuição usada na OpenCV)\n",
        " - mediana \n",
        "3. Relate as observações visíveis nas imagens de saída com os filtros usados, descrevendo o comportamento visual em relação as bordas, ruídos e esmaecimento da imagem com os diferentes kernels\n",
        "\n",
        "#### Dicas\n",
        " - Você pode adicionar ruído nas imagens usando a função random_noise: `from skimage.util import random_noise`. Cuidado com o retorno da função, talvez seja necessário regularizar a mesma novamente para o intervalo de 0 à 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_padding(img, padding_height, padding_width):\n",
        "    n, m = img.shape\n",
        "    \n",
        "    padded_img = np.zeros((n + padding_height * 2, m + padding_width * 2))\n",
        "    padded_img[padding_height : n + padding_height, padding_width : m + padding_width] = img\n",
        "    \n",
        "    return padded_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chgyg8wWTHOG"
      },
      "outputs": [],
      "source": [
        "def conv2d(img, kernel, padding=True):\n",
        "    # Get dimensions of the kernel\n",
        "    k_height, k_width = kernel.shape  # Atribui valor à variável k_height, k_width\n",
        "    \n",
        "    # Get dimensions of the image\n",
        "    img_height, img_width = img.shape  # Atribui valor à variável img_height, img_width\n",
        "    \n",
        "    # Calculate padding required\n",
        "    pad_height = k_height // 2  # Atribui valor à variável pad_height\n",
        "    pad_width = k_width // 2  # Atribui valor à variável pad_width\n",
        "\n",
        "    # Create a padded version of the image to handle edges\n",
        "    if padding == True:\n",
        "        padded_img = add_padding(img, pad_height, pad_width)  # Atribui valor à variável padded_img\n",
        "        \n",
        "    print(padded_img)\n",
        "\n",
        "    # Initialize an output image with zeros\n",
        "    output = np.zeros((img_height, img_width), dtype=float)  # Atribui valor à variável output\n",
        "\n",
        "    # Perform convolution\n",
        "    \n",
        "            \n",
        "    return np.array(output, dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.  26.  34.  29.  35.  48.  64.  83.  81.  61.  27.   0.]\n",
            " [  0.  31.  47.  43.  49.  72.  91. 115. 132. 123.  14.   0.]\n",
            " [  0.  28.  54.  60.  68.  72.  62.  94. 157. 129.  16.   0.]\n",
            " [  0.  37.  46.  49.  60.  60.  40.  54. 102.  51.  14.   0.]\n",
            " [  0.  21.  22.  27.  28.  29.  32.  33.  29.  18.  23.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
            "[[ 15  23  26  30  39  52  62  66  48  25]\n",
            " [ 24  39  46  52  62  77  97 108  82  41]\n",
            " [ 27  43  52  59  63  73  94 106  82  38]\n",
            " [ 23  38  46  50  50  52  66  74  59  27]\n",
            " [ 13  22  25  28  27  27  32  31  26  11]]\n",
            "[[ 38  37  42  49  63  83 100 107  79  74]\n",
            " [ 39  39  47  53  62  78  98 108  82  76]\n",
            " [ 43  44  53  59  64  73  94 106  82  72]\n",
            " [ 37  38  46  50  50  53  67  74  60  50]\n",
            " [ 36  37  43  47  45  45  54  55  45  32]]\n",
            "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.  26.  34.  29.  35.  48.  64.  83.  81.  61.  27.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.  31.  47.  43.  49.  72.  91. 115. 132. 123.  14.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.  28.  54.  60.  68.  72.  62.  94. 157. 129.  16.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.  37.  46.  49.  60.  60.  40.  54. 102.  51.  14.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.  21.  22.  27.  28.  29.  32.  33.  29.  18.  23.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.]]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGbbZhqPTHOG"
      },
      "source": [
        "### Sharpening\n",
        "\n",
        "4. Implemente os filtros de sharpening, utilizando as diferentes mascarás apresentadas no livro de referência da disciplina:\n",
        " - Laplaciano (figura 3.37)\n",
        " - Sharpening implementado na figura 3.38\n",
        " - Unsharp Masking e Highboost Filtering\n",
        " - Implemente os detectores de borda Laplaciano, Roberts e Sobel\n",
        " - Utilize a função Canny da OpenCV na mesma imagem usando nos outros detectores\n",
        " \n",
        "5. Relate as observações visíveis nas imagens de saída com os filtros usados, descrevendo o comportamento visual em relação as bordas, ruídos e esmaecimento da imagem com os diferentes kernels e para os diferentes algoritmos\n",
        "6. Você observa uma discrepante melhoria na detecção de bordas pelo Canny em comparação aos outros 3 que justifique a complexidade adicional?\n",
        "7. Aplique o filtro Sobel pós operação com um filtro de suavização (a sua escolha) e compare com a saída do Canny. Descreva suas observações técnicas sobre o comportamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYUu1wKoTHOG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cjlIt6CTHOG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Prática - Filtragem Espacial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

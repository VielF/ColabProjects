{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VielF/ColabProjects/blob/main/Segmenta%C3%A7%C3%A3o_por_Crescimento_de_Regi%C3%B5es_Parte_2_Algoritmos_Avan%C3%A7ados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Universidade do Vale do Itajaí<br>\n",
        "Escola Politécnica<br>\n",
        "Processamento Digital de Imagens\n",
        "\n",
        "# Exercício Segmentação Clássica - Sem Deep Learning\n",
        "\n",
        "### Tutoriais da OpenCV\n",
        "\n",
        "- https://docs.opencv.org/master/d9/df8/tutorial_root.html\n",
        "- https://www.geeksforgeeks.org/opencv-python-tutorial/"
      ],
      "metadata": {
        "id": "kS6Eo1eh67QA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a4AkGZO64Z8"
      },
      "source": [
        "# Segmentação por Crescimento de Regiões - Parte 2 - Algoritmos Avançados\n",
        "\n",
        "A busca pelo sonho de consumo do algoritmo genérico para dividir uma imagem nos objetos ali representados levou ao desenvolvimento de algoritmos de segmentação bastante elaborados, que tentavam unir várias técnicas diferentes e várias representações diferentes do conteúdo de uma imagem: grafos dos objetos na imagem, representação de longos gradientes suaves por grandes regiões da imagem representando o mesmo objeto que variava de luminosidade, similaridade de pixel baseada em características específicas de imagens de satélite ou outras e por aí vai. Alguns players de peso como a NASA tentaram a sua sorte neste tipo de algoritmo.\n",
        "\n",
        "A maioria desses algoritmos foram implementados em linguagens de programação compiladas e existiram apenas na forma de executáveis que podiam ser baixados ou de código fonte em linguagem C ou C++. Como a pesquisa nesses algoritmos é anterior ao grande sucesso da linguagem Python, que estamos vendo agora, e as pesquisas agora estão voltadas para o desenvolvimento de algoritmos baseados em aprendizado profundo, muito poucos dos algoritmos que discutimos na nossa aula de segmentação avançada acabaram recebendo uma implementação em Python. O algoritmo de segmentação baseado em gráficos de Felzenszwalb & Huttenlocher, que possui um nome tão prosaico que ele só é citado pelas suas iniciais FH, é um dos poucos exemplos que nós podemos executar em Python. Abaixo vão alguns exemplos de sua execução.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyhlLIkC64Z9"
      },
      "source": [
        "### Inicializações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXjaZpsv64Z9"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Mtto_C64Z9"
      },
      "source": [
        "## Métodos baseados em gráficos: o algoritmo Felzenszwalb & Huttenlocher\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR90gzzv64Z9"
      },
      "source": [
        "### SciKit F&H com imagens em tons de cinza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0b72c5ea818e43a28954eddc02ec7152"
          ]
        },
        "id": "4LUvt_Xg64Z-",
        "outputId": "7adb401f-7e8b-47ad-deb1-6a008677f6b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b72c5ea818e43a28954eddc02ec7152",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=100, description='scale', max=300, min=-100), FloatSlider(value=0.5, des…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ipywidgets import interact, interactive, interact_manual\n",
        "from skimage.data import astronaut\n",
        "from skimage.segmentation import felzenszwalb\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "import cv2\n",
        "\n",
        "image = cv2.imread(\"/content/dataSeg/ct-02.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "#image = img_as_float(img[::2, ::2])\n",
        "\n",
        "\n",
        "def my_fh(scale=100, sigma=0.5, min_size=50, colormap='magma'):\n",
        "    global image\n",
        "    colormap = eval('plt.cm.' + colormap)\n",
        "    segments_fh = felzenszwalb(image, scale=scale, sigma=sigma, min_size=min_size)\n",
        "\n",
        "    fig, ax = plt.subplots(ncols=2, figsize=(15, 7), sharex=True, sharey=True)\n",
        "\n",
        "    ax[0].imshow(mark_boundaries(image, segments_fh))\n",
        "    ax[0].set_title('Original com limites: F&H')\n",
        "\n",
        "    ax[1].imshow(segments_fh, cmap=colormap, interpolation='nearest')\n",
        "    ax[1].set_title('Segmentos: Felzenszwalb & Huttenlocher')\n",
        "\n",
        "    for a in ax:\n",
        "        a.set_axis_off()\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "interactive(my_fh, scale=100, sigma=0.5, min_size=50, colormap = ['nipy_spectral', 'hot', 'magma', 'seismic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wAA0ZWD64Z_"
      },
      "source": [
        "### SciKit F&H with Color Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "29c229b6ea85499680e4e2c41648b614"
          ]
        },
        "id": "JPmapd6r64Z_",
        "outputId": "6a9aeb1a-6438-4863-dbb9-0fe63d8b8623"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29c229b6ea85499680e4e2c41648b614",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=100, description='scale', max=300, min=-100), FloatSlider(value=0.5, des…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ipywidgets import interact, interactive, interact_manual\n",
        "from skimage.data import astronaut\n",
        "from skimage.segmentation import felzenszwalb\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "\n",
        "img = cv2.imread(\"/content/dataSeg/car-01.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "image = img_as_float(img[::2, ::2])\n",
        "\n",
        "\n",
        "def my_fh(scale=100, sigma=0.5, min_size=50):\n",
        "    global image\n",
        "    segments_fh = felzenszwalb(image, scale=scale, sigma=sigma, min_size=min_size)\n",
        "\n",
        "    fig, ax = plt.subplots(ncols=2, figsize=(19, 7), sharex=True, sharey=True)\n",
        "\n",
        "    ax[0].imshow(mark_boundaries(image, segments_fh))\n",
        "    ax[0].set_title('Original com limites: F&H')\n",
        "\n",
        "    ax[1].imshow(segments_fh, cmap=plt.cm.nipy_spectral, interpolation='nearest')\n",
        "    ax[1].set_title('Segmentos: Felzenszwalb & Huttenlocher')\n",
        "\n",
        "    for a in ax:\n",
        "        a.set_axis_off()\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "interactive(my_fh, scale=100, sigma=0.5, min_size=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK9TSDCY64aA"
      },
      "source": [
        "### Implementação PEGBIS F&H\n",
        "\n",
        "Aqui usaremos o **PEGBIS** *(Python Efficient Graph-Based Image Segmentation)*, uma implementação Python por Ghassem Alaee do \"Efficient Graph-Based Image Segmentation\" paper written by P. Felzenszwalb, D. Huttenlocher. O documento está disponível: http://cs.brown.edu/~pff/papers/seg-ijcv.pdf. A implementação C++ foi escrita pelo autor e está disponível em: http://cs.brown.edu/~pff/segment/.  Você encontrará a implementação do autor original em https://github.com/salaee/pegbis. A versão que estamos usando aqui teve algumas adaptações e atualizações do Python do Prof. Aldo von Wangenheim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM1BLWnV64aA"
      },
      "outputs": [],
      "source": [
        "# Faça isso uma vez (ou sempre que reiniciar o kernel se estiver usando o Colab)\n",
        "# O código abaixo baixa a versão armazenada no github\n",
        "# parâmetros wget:\n",
        "# --backups=1 : renomeia o arquivo original com o sufixo .1 e grava o novo arquivo no nome de arquivo pretendido\n",
        "# -q : execute silenciosamente, a menos que haja um erro\n",
        "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/segment_graph.py\n",
        "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/filter.py\n",
        "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/fh_segment.py\n",
        "!wget --backups=1 -q https://raw.githubusercontent.com/awangenh/pegbis/master/disjoint_set.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b0f5d5121cc24cb6b13752ce739b46c0"
          ]
        },
        "id": "EkWo0SeQ64aA",
        "outputId": "c559124e-01ea-427b-fbfa-6679c61eb466"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0f5d5121cc24cb6b13752ce739b46c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=100, description='scale', max=1000, min=1), FloatSlider(value=0.5, descr…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<function __main__.my_pegbis(scale=100, sigma=0.5, min_size=50)>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# Segment an image:\n",
        "# Returns a color image representing the segmentation.\n",
        "#\n",
        "# Inputs:\n",
        "#           in_image: image to segment.\n",
        "#           sigma: to smooth the image.\n",
        "#           k: constant for threshold function.\n",
        "#           min_size: minimum component size (enforced by post-processing stage).\n",
        "#\n",
        "# Returns:\n",
        "#           num_ccs: number of connected components in the segmentation.\n",
        "# --------------------------------------------------------------------------------\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from filter import *\n",
        "from segment_graph import *\n",
        "from fh_segment import *\n",
        "import time\n",
        "from ipywidgets import interact, interactive, interact_manual\n",
        "\n",
        "sigma = 0.5\n",
        "scale = 100\n",
        "min_size = 50\n",
        "input_path = \"/content/dataSeg/car-01.jpg\"\n",
        "\n",
        "# Carregando a imagem\n",
        "#input_image = ndimage.imread(input_path, flatten=False, mode=None)\n",
        "input_image = plt.imread(input_path)\n",
        "\n",
        "def my_pegbis(scale=100, sigma=0.5, min_size=50):\n",
        "    global input_image\n",
        "\n",
        "    print(\"processing...\")\n",
        "    output_image, elapsed_time = fh_segment(input_image, sigma, scale, min_size)\n",
        "    print(\"Execution time: \" + str(int(elapsed_time / 60)) + \" minute(s) and \" + str(int(elapsed_time % 60)) + \" seconds\")\n",
        "    # exibindo o resultado\n",
        "    fig, ax = plt.subplots(ncols=2, figsize=(14, 7), sharex=True, sharey=True)\n",
        "\n",
        "    ax[0].imshow(input_image)\n",
        "    ax[0].set_title('Original')\n",
        "\n",
        "    ax[1].imshow(output_image)\n",
        "    ax[1].set_title('Segments: Felzenszwalb & Huttenlocher')\n",
        "\n",
        "    for a in ax:\n",
        "        a.set_axis_off()\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "interact_manual(my_pegbis, scale=(1, 1000), sigma=(0.1, 3.0), min_size=(10, 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts5KQGSr64aB"
      },
      "source": [
        "# Créditos\n",
        "\n",
        "* Truques gerais para exibir imagens vieram daqui: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
        "* Também usamos algumas dicas gerais de: https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py\n",
        "* Também usamos material do Professor Aldo von Wangenheim da UFSC"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "varInspector": {
      "cols": {
        "lenName": "20",
        "lenType": "20",
        "lenVar": "60"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}